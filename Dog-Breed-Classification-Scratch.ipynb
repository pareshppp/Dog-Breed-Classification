{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Classification using Pytorch - Part 1\n",
    "## (Creating model from Scratch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this post, we will create an Image classification model using PyTorch with the goal of Recognizing Breed of Dogs from images. For this project, we will create the model from scratch. We will look into Transfer Learning based models in future posts. \n",
    "\n",
    "The image below displays potential sample output of the finished project.\n",
    "\n",
    "![Sample Dog Output](images/sample_dog_output.png)\n",
    "\n",
    "There are a total of 133 Dog-Breeds (classes) in the source data. So, a random guess will provide a correct answer roughly 1 in 133 times, which corresponds to an accuracy of less than 1%. \n",
    "\n",
    "Dog Breed Classification is an exceptionally difficult problem because:\n",
    "\n",
    "Different dog breeds can look similar.\n",
    "\n",
    "Brittany | Welsh Springer Spaniel\n",
    "- | - \n",
    "<img src=\"images/Brittany_02625.jpg\" width=\"100\"> | <img src=\"images/Welsh_springer_spaniel_08203.jpg\" width=\"200\">\n",
    "\n",
    "And same dog breed can have different looking dogs.\n",
    "\n",
    "Yellow Labrador | Chocolate Labrador | Black Labrador\n",
    "- | -\n",
    "<img src=\"images/Labrador_retriever_06457.jpg\" width=\"150\"> | <img src=\"images/Labrador_retriever_06455.jpg\" width=\"240\"> | <img src=\"images/Labrador_retriever_06449.jpg\" width=\"220\">\n",
    "\n",
    "The model will have to account for all of these factors to produce a high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Datasets\n",
    "\n",
    "The first step is to load-in the Images and check the total size of our dataset.\n",
    "\n",
    "* The Dog Images Dataset can be downloaded from here: [dog dataset](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip). Unzip the folder and place it in this project's home directory, at the location `/dogImages`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8351 total dog images.\n"
     ]
    }
   ],
   "source": [
    "# load filenames for dog images\n",
    "dog_files = np.array(glob(\"dogImages/*/*/*\"))\n",
    "\n",
    "# print number of images in dataset\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check CUDA Availability\n",
    "\n",
    "Check if GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters\n",
    "\n",
    "Define the parameters needed in data loader and model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters\n",
    "n_epochs = 20\n",
    "num_classes = 133\n",
    "num_workers = 0\n",
    "batch_size = 10\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders for the Dog Dataset\n",
    "\n",
    "In the next step we will do the following:\n",
    "1. Define Transformations that will be applied to the images using `torchvision.transforms`. Transformations are also known as Augmentation. This is a pre-processing step and it helps the model to generalize to new data much better.\n",
    "2. Load the image data using `torchvision.datasets.ImageFolder` and apply the transformations.\n",
    "3. Create Dataloaders using `torch.utils.data.DataLoader`.  \n",
    "\n",
    "**Note:**\n",
    "- We have created dictionaries for all three steps that are divided into train, validation and test sets.\n",
    "- The Image Resize shape and mean & standard-deviation values for Normalization module were chosen so as to replicate the VGG16 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data loaders for training, validation, and test sets\n",
    "trans = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'train': datasets.ImageFolder('dogImages/train', transform=trans['train']),\n",
    "    'valid': datasets.ImageFolder('dogImages/valid', transform=trans['valid']),\n",
    "    'test': datasets.ImageFolder('dogImages/test', transform=trans['test'])\n",
    "}\n",
    "\n",
    "loaders_scratch = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, num_workers=num_workers, shuffle=True),\n",
    "    'valid': DataLoader(data['valid'], batch_size=batch_size, num_workers=num_workers, shuffle=True),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Train DataLoader: 6680\n",
      "Size of Validation DataLoader: 835\n",
      "Size of Test DataLoader: 836\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of Train DataLoader: {len(loaders_scratch['train'].dataset)}\")\n",
    "print(f\"Size of Validation DataLoader: {len(loaders_scratch['valid'].dataset)}\")\n",
    "print(f\"Size of Test DataLoader: {len(loaders_scratch['test'].dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "Next, we will define a class `Net` which will create our model architecture. The configuration used here is a simplified (smaller) version of VGG16 model.\n",
    "\n",
    "After defining the architecture we instantiate the class and move the model to GPU (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "# The above configuration is the complete VGG16 model configuration. We will use a smaller version of this.\n",
    "\n",
    "cfg = [8, 'M', 16, 'M', 32, 'M', 64, 'M', 128, 'M']\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, model_cfg=cfg):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        self.features = self.make_layers(model_cfg)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Define forward behavior\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def make_layers(self, model_cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for l in model_cfg:\n",
    "            if l == 'M':\n",
    "                layers.extend([nn.MaxPool2d(kernel_size=2, stride=2)])\n",
    "            else:\n",
    "                layers.extend([\n",
    "                    nn.Conv2d(in_channels, l, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(l),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                ])\n",
    "                in_channels = l\n",
    "                \n",
    "        # layers.extend([nn.AvgPool2d(kernel_size=1, stride=1)])\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# instantiate the CNN\n",
    "model_scratch = Net(cfg)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Loss Function and Optimizer\n",
    "\n",
    "We have chosen `CrossEntropyLoss` as our loss function and `Stochastic Gradient Descent` as our optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## select loss function\n",
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "\n",
    "## select optimizer\n",
    "optimizer_scratch = optim.SGD(params=model_scratch.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate the Model\n",
    "\n",
    "We define a function for Training and Validation. It calculates a running train & validation loss and saves the model whenever the validation loss decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            if batch_idx % 200 == 0:\n",
    "                print(f\"Training Batch: {batch_idx}+/{len(loaders['train'])}\")\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            valid_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            if batch_idx % 200 == 0:\n",
    "                print(f\"Validation Batch: {batch_idx}+/{len(loaders['valid'])}\")\n",
    "\n",
    "        \n",
    "        train_loss = train_loss / len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss / len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print(f'Epoch: {epoch} \\tTraining Loss: {train_loss} \\tValidation Loss: {valid_loss}')\n",
    "        \n",
    "        # save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print(f'Validation loss decreased from {valid_loss_min} to {valid_loss}.\\nSaving Model...')\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the actual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 1 \tTraining Loss: 4.850923725944793 \tValidation Loss: 4.672233612951405\n",
      "Validation loss decreased from inf to 4.672233612951405.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 2 \tTraining Loss: 4.692525517797756 \tValidation Loss: 4.575351500939466\n",
      "Validation loss decreased from 4.672233612951405 to 4.575351500939466.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 3 \tTraining Loss: 4.611959935662275 \tValidation Loss: 4.490825558850865\n",
      "Validation loss decreased from 4.575351500939466 to 4.490825558850865.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 4 \tTraining Loss: 4.54853381939277 \tValidation Loss: 4.377603702202529\n",
      "Validation loss decreased from 4.490825558850865 to 4.377603702202529.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 5 \tTraining Loss: 4.480644456640689 \tValidation Loss: 4.364550402064523\n",
      "Validation loss decreased from 4.377603702202529 to 4.364550402064523.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 6 \tTraining Loss: 4.428592964560686 \tValidation Loss: 4.26392102669813\n",
      "Validation loss decreased from 4.364550402064523 to 4.26392102669813.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 7 \tTraining Loss: 4.3614827144645645 \tValidation Loss: 4.165594831912103\n",
      "Validation loss decreased from 4.26392102669813 to 4.165594831912103.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 8 \tTraining Loss: 4.312848891326767 \tValidation Loss: 4.184076757488136\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 9 \tTraining Loss: 4.268599698643484 \tValidation Loss: 4.108313751791766\n",
      "Validation loss decreased from 4.165594831912103 to 4.108313751791766.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 10 \tTraining Loss: 4.19705679530869 \tValidation Loss: 4.119787540264472\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 11 \tTraining Loss: 4.148586997371948 \tValidation Loss: 4.03563191648015\n",
      "Validation loss decreased from 4.108313751791766 to 4.03563191648015.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 12 \tTraining Loss: 4.107213460399719 \tValidation Loss: 3.956797694017787\n",
      "Validation loss decreased from 4.03563191648015 to 3.956797694017787.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 13 \tTraining Loss: 4.062709527458259 \tValidation Loss: 3.9428881984984803\n",
      "Validation loss decreased from 3.956797694017787 to 3.9428881984984803.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 14 \tTraining Loss: 4.02488235228076 \tValidation Loss: 3.932503150608725\n",
      "Validation loss decreased from 3.9428881984984803 to 3.932503150608725.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 15 \tTraining Loss: 3.9810512015919484 \tValidation Loss: 3.8608019951574817\n",
      "Validation loss decreased from 3.932503150608725 to 3.8608019951574817.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 16 \tTraining Loss: 3.937334066022656 \tValidation Loss: 3.8132093980640707\n",
      "Validation loss decreased from 3.8608019951574817 to 3.8132093980640707.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 17 \tTraining Loss: 3.9022414184615997 \tValidation Loss: 3.788482242001745\n",
      "Validation loss decreased from 3.8132093980640707 to 3.788482242001745.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 18 \tTraining Loss: 3.8819510519147635 \tValidation Loss: 3.6973510959191236\n",
      "Validation loss decreased from 3.788482242001745 to 3.6973510959191236.\n",
      "Saving Model...\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 19 \tTraining Loss: 3.8232821276087963 \tValidation Loss: 3.7056023831852896\n",
      "Training Batch: 0+/668\n",
      "Training Batch: 200+/668\n",
      "Training Batch: 400+/668\n",
      "Training Batch: 600+/668\n",
      "Validation Batch: 0+/84\n",
      "Epoch: 20 \tTraining Loss: 3.7742863857817506 \tValidation Loss: 3.6766837257111145\n",
      "Validation loss decreased from 3.6973510959191236 to 3.6766837257111145.\n",
      "Saving Model...\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "if use_cuda:\n",
    "    model_scratch = model_scratch.cuda()\n",
    "\n",
    "model_scratch = train(n_epochs, loaders_scratch, model_scratch, optimizer_scratch, \n",
    "                      criterion_scratch, use_cuda, 'model_scratch.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "model_scratch.load_state_dict(torch.load('model_scratch.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "We compare the predicted outputs with target to get the number of correct predictions and then calculate the pecentage accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.744145\n",
      "\n",
      "\n",
      "Test Accuracy: 11% (97/836)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        # test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    test_loss = test_loss / len(loaders['test'].dataset)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# call test function    \n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "With only 20 epochs of training we achieved an accuracy of 11%. 11% may seem very low but remember that random-chance would have given us an accuracy of less than 1%. To get a higher accuracy we need to use more complex models than the one we used here. So, in the next post we will use Transfer Learning and work on VGG16 architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
